{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ensemble classification with Forest and Qiskit devices\n======================================================\n\n::: {.meta}\n:property=\\\"og:description\\\": We demonstrate how two QPUs can be\ncombined in parallel to help solve a machine learning classification\nproblem, using PyTorch and PennyLane. :property=\\\"og:image\\\":\n<https://pennylane.ai/qml/_images/ensemble_diagram.png>\n:::\n\n*Author: PennyLane dev team. Last updated: 13 Dec 2021.*\n\nThis tutorial outlines how two QPUs can be combined in parallel to help\nsolve a machine learning classification problem.\n\nWe use the `forest.qvm` device to simulate one QPU and the `qiskit.aer`\ndevice to simulate another. Each QPU makes an independent prediction,\nand an ensemble model is formed by choosing the prediction of the most\nconfident QPU. The iris dataset is used in this tutorial, consisting of\nthree classes of iris flower. Using a pre-trained model and the PyTorch\ninterface, we\\'ll see that ensembling allows the QPUs to specialize\ntowards different classes.\n\nLet\\'s begin by importing the prerequisite libraries:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pennylane as qml\nimport sklearn.datasets\nimport sklearn.decomposition\nimport torch\nfrom matplotlib.lines import Line2D\nfrom matplotlib.patches import Patch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This tutorial requires the `pennylane-forest` and `pennylane-qiskit`\npackages, which can be installed by following the instructions\n[here](https://pennylane.ai/install.html). We also make use of the\n[PyTorch interface\n\\<https://pennylane.readthedocs.io/en/stable/introduction\n/interfaces.html\\>](), which can be installed from\n[here](https://pytorch.org/get-started/locally/).\n\nLoad data\n=========\n\nThe next step is to load the iris dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_features = 2\nn_classes = 3\nn_samples = 150\n\ndata = sklearn.datasets.load_iris()\nx = data[\"data\"]\ny = data[\"target\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We shuffle the data and then embed the four features into a\ntwo-dimensional space for ease of plotting later on. The first two\nprincipal components of the data are used.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.random.seed(1967)\nx, y = zip(*np.random.permutation(list(zip(x, y))))\n\npca = sklearn.decomposition.PCA(n_components=n_features)\npca.fit(x)\nx = pca.transform(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will be encoding these two features into quantum circuits using\n`~.pennylane.RX`{.interpreted-text role=\"class\"} rotations, and hence\nrenormalize our features to be between $[-\\pi, \\pi]$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_min = np.min(x, axis=0)\nx_max = np.max(x, axis=0)\n\nx = 2 * np.pi * (x - x_min) / (x_max - x_min) - np.pi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data is split between a training and a test set. This tutorial uses\na model that is pre-trained on the training set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "split = 125\n\nx_train = x[:split]\nx_test = x[split:]\ny_train = y[:split]\ny_test = y[split:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, let\\'s take a quick look at our data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "colours = [\"#ec6f86\", \"#4573e7\", \"#ad61ed\"]\n\n\ndef plot_points(x_train, y_train, x_test, y_test):\n    c_train = []\n    c_test = []\n\n    for y in y_train:\n        c_train.append(colours[y])\n\n    for y in y_test:\n        c_test.append(colours[y])\n\n    plt.scatter(x_train[:, 0], x_train[:, 1], c=c_train)\n    plt.scatter(x_test[:, 0], x_test[:, 1], c=c_test, marker=\"x\")\n\n    plt.xlabel(\"Feature 1\", fontsize=16)\n    plt.ylabel(\"Feature 2\", fontsize=16)\n\n    ax = plt.gca()\n    ax.set_aspect(1)\n\n    c_transparent = \"#00000000\"\n\n    custom_lines = [\n        Patch(facecolor=colours[0], edgecolor=c_transparent, label=\"Class 0\"),\n        Patch(facecolor=colours[1], edgecolor=c_transparent, label=\"Class 1\"),\n        Patch(facecolor=colours[2], edgecolor=c_transparent, label=\"Class 2\"),\n        Line2D([0], [0], marker=\"o\", color=c_transparent, label=\"Train\",\n               markerfacecolor=\"black\", markersize=10),\n        Line2D([0], [0], marker=\"x\", color=c_transparent, label=\"Test\",\n               markerfacecolor=\"black\", markersize=10),\n    ]\n\n    ax.legend(handles=custom_lines, bbox_to_anchor=(1.0, 0.75))\n\n\nplot_points(x_train, y_train, x_test, y_test)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/demonstrations/ensemble_multi_qpu/ensemble_multi_qpu_001.png){.align-center\nwidth=\"80.0%\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This plot shows us that class 0 points can be nicely separated, but that\nthere is an overlap between points from classes 1 and 2.\n\nDefine model\n============\n\nOur model is summarized in the figure below. We use two 4-qubit devices:\n`4q-qvm` from the PennyLane-Forest plugin and `qiskit.aer` from the\nPennyLane-Qiskit plugin.\n\nData is input using `~.pennylane.RX`{.interpreted-text role=\"class\"}\nrotations and then a different circuit is enacted for each device with a\nunique set of trainable parameters. The output of both circuits is a\n`~.pennylane.PauliZ`{.interpreted-text role=\"class\"} measurement on\nthree of the qubits. This is then fed through a softmax function,\nresulting in two 3-dimensional probability vectors corresponding to the\n3 classes.\n\nFinally, the ensemble model chooses the QPU which is most confident\nabout its prediction (i.e., the class with the highest overall\nprobability over all QPUs) and uses that to make a prediction.\n\n![](/demonstrations/ensemble_multi_qpu/ensemble_diagram.png){.align-center\nwidth=\"80.0%\"}\n\nQuantum nodes\n-------------\n\nWe begin by defining the two quantum devices and the circuits to be run\non them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_wires = 4\n\ndev0 = qml.device(\"forest.qvm\", device=\"4q-qvm\")\ndev1 = qml.device(\"qiskit.aer\", wires=4)\ndevs = [dev0, dev1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.note}\n::: {.title}\nNote\n:::\n\nIf you have access to Rigetti hardware, you can swap out `forest.qvm`\nfor `forest.qpu` and specify the hardware device to run on. Users with\naccess to the IBM Q Experience can swap `qiskit.aer` for `qiskit.ibmq`\nand specify their chosen backend (see\n[here](https://pennylane-qiskit.readthedocs.io/en/latest/gettingstarted.html#ibm-q-experience)).\n:::\n\n::: {.warning}\n::: {.title}\nWarning\n:::\n\nRigetti\\'s QVM and Quil Compiler services must be running for this\ntutorial to execute. They can be installed by consulting the [Rigetti\ndocumentation](http://docs.rigetti.com/qcs/) or, for users with Docker,\nby running:\n\n``` {.bash}\ndocker run -d -p 5555:5555 rigetti/quilc -R -p 5555\ndocker run -d -p 5000:5000 rigetti/qvm -S -p 5000\n```\n:::\n\nThe circuits for both QPUs are shown in the figure below:\n\n![](/demonstrations/ensemble_multi_qpu/diagram_circuits.png){.align-center\nwidth=\"80.0%\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def circuit0(params, x=None):\n    for i in range(n_wires):\n        qml.RX(x[i % n_features], wires=i)\n        qml.Rot(*params[1, 0, i], wires=i)\n\n    qml.CZ(wires=[1, 0])\n    qml.CZ(wires=[1, 2])\n    qml.CZ(wires=[3, 0])\n\n    for i in range(n_wires):\n        qml.Rot(*params[1, 1, i], wires=i)\n    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(2))\n\n\ndef circuit1(params, x=None):\n    for i in range(n_wires):\n        qml.RX(x[i % n_features], wires=i)\n        qml.Rot(*params[0, 0, i], wires=i)\n\n    qml.CZ(wires=[0, 1])\n    qml.CZ(wires=[1, 2])\n    qml.CZ(wires=[1, 3])\n\n    for i in range(n_wires):\n        qml.Rot(*params[0, 1, i], wires=i)\n    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We finally combine the two devices into a\n`~.pennylane.QNodeCollection`{.interpreted-text role=\"class\"} that uses\nthe PyTorch interface:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "qnodes = qml.QNodeCollection(\n    [qml.QNode(circuit0, dev0, interface=\"torch\"),\n     qml.QNode(circuit1, dev1, interface=\"torch\")]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Postprocessing into a prediction\n================================\n\nThe `predict_point` function below allows us to find the ensemble\nprediction, as well as keeping track of the individual predictions from\neach QPU.\n\nWe include a `parallel` keyword argument for evaluating the\n`~.pennylane.QNodeCollection`{.interpreted-text role=\"class\"} in a\nparallel asynchronous manner. This feature requires the `dask` library,\nwhich can be installed using `pip install \"dask[delayed]\"`. When\n`parallel=True`, we are able to make predictions faster because we do\nnot need to wait for one QPU to output before running on the other.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def decision(softmax):\n    return int(torch.argmax(softmax))\n\n\ndef predict_point(params, x_point=None, parallel=True):\n    results = qnodes(params, x=x_point, parallel=parallel)\n    softmax = torch.nn.functional.softmax(results, dim=1)\n    choice = torch.where(softmax == torch.max(softmax))[0][0]\n    chosen_softmax = softmax[choice]\n    return decision(chosen_softmax), decision(softmax[0]), decision(softmax[1]), int(choice)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, let\\'s define a function to make a predictions over multiple data\npoints.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def predict(params, x=None, parallel=True):\n    predictions_ensemble = []\n    predictions_0 = []\n    predictions_1 = []\n    choices = []\n\n    for i, x_point in enumerate(x):\n        if i % 10 == 0 and i > 0:\n            print(\"Completed up to iteration {}\".format(i))\n        results = predict_point(params, x_point=x_point, parallel=parallel)\n        predictions_ensemble.append(results[0])\n        predictions_0.append(results[1])\n        predictions_1.append(results[2])\n        choices.append(results[3])\n\n    return predictions_ensemble, predictions_0, predictions_1, choices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make predictions\n================\n\nTo test our model, we first load a pre-trained set of parameters which\ncan also be downloaded by clicking\n`here <../demonstrations/ensemble_multi_qpu/params.npy>`{.interpreted-text\nrole=\"download\"}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params = np.load(\"ensemble_multi_qpu/params.npy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then make predictions for the training and test datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Predicting on training dataset\")\np_train, p_train_0, p_train_1, choices_train = predict(params, x=x_train)\nprint(\"Predicting on test dataset\")\np_test, p_test_0, p_test_1, choices_test = predict(params, x=x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\nPredicting on training dataset\nCompleted up to iteration 10\nCompleted up to iteration 20\nCompleted up to iteration 30\nCompleted up to iteration 40\nCompleted up to iteration 50\nCompleted up to iteration 60\nCompleted up to iteration 70\nCompleted up to iteration 80\nCompleted up to iteration 90\nCompleted up to iteration 100\nCompleted up to iteration 110\nCompleted up to iteration 120\nPredicting on test dataset\nCompleted up to iteration 10\nCompleted up to iteration 20\n```\n:::\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analyze performance\n===================\n\nThe last thing to do is test how well the model performs. We begin by\nlooking at the accuracy.\n\nAccuracy\n--------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def accuracy(predictions, actuals):\n    count = 0\n\n    for i in range(len(predictions)):\n        if predictions[i] == actuals[i]:\n            count += 1\n\n    accuracy = count / (len(predictions))\n    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Training accuracy (ensemble): {}\".format(accuracy(p_train, y_train)))\nprint(\"Training accuracy (QPU0):  {}\".format(accuracy(p_train_0, y_train)))\nprint(\"Training accuracy (QPU1):  {}\".format(accuracy(p_train_1, y_train)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\nTraining accuracy (ensemble): 0.824\nTraining accuracy (QPU0):  0.648\nTraining accuracy (QPU1):  0.28\n```\n:::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Test accuracy (ensemble): {}\".format(accuracy(p_test, y_test)))\nprint(\"Test accuracy (QPU0):  {}\".format(accuracy(p_test_0, y_test)))\nprint(\"Test accuracy (QPU1):  {}\".format(accuracy(p_test_1, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\nTest accuracy (ensemble): 0.72\nTest accuracy (QPU0):  0.56\nTest accuracy (QPU1):  0.24\n```\n:::\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These numbers tell us a few things:\n\n-   On both training and test datasets, the ensemble model outperforms\n    the predictions from each QPU. This provides a nice example of how\n    QPUs can be used in parallel to gain a performance advantage.\n-   The accuracy of QPU0 is much higher than the accuracy of QPU1. This\n    does not mean that one device is intrinsically better than the\n    other. In fact, another set of parameters can lead to QPU1 becoming\n    more accurate. We will see in the next section that the difference\n    in accuracy is due to specialization of each QPU, which leads to\n    overall better performance of the ensemble model.\n-   The test accuracy is lower than the training accuracy. Here our\n    focus is on analyzing the performance of the ensemble model, rather\n    than minimizing the generalization error.\n\nChoice of QPU\n=============\n\nIs there a link between the class of a datapoint and the QPU chosen to\nmake the prediction in the ensemble model? Let\\'s investigate.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Combine choices_train and choices_test to simplify analysis\nchoices = np.append(choices_train, choices_test)\nprint(\"Choices: {}\".format(choices))\nprint(\"Choices counts: {}\".format(Counter(choices)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\nChoices: [0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0\n 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0\n 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0\n 0 0]\nChoices counts: Counter({0: 110, 1: 40})\n```\n:::\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following lines keep track of choices and corresponding predictions\nin the ensemble model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "predictions = np.append(p_train, p_test)\nchoice_vs_prediction = np.array([(choices[i], predictions[i]) for i in range(n_samples)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can hence find the predictions each QPU was responsible for.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "choices_vs_prediction_0 = choice_vs_prediction[choice_vs_prediction[:, 0] == 0]\nchoices_vs_prediction_1 = choice_vs_prediction[choice_vs_prediction[:, 0] == 1]\npredictions_0 = choices_vs_prediction_0[:, 1]\npredictions_1 = choices_vs_prediction_1[:, 1]\n\n\nexpl = \"When QPU{} was chosen by the ensemble, it made the following distribution of \" \\\n       \"predictions:\\n{}\"\nprint(expl.format(\"0\", Counter(predictions_0)))\nprint(\"\\n\" + expl.format(\"1\", Counter(predictions_1)))\nprint(\"\\nDistribution of classes in iris dataset: {}\".format(Counter(y)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.rst-class}\nsphx-glr-script-out\n\nOut:\n\n``` {.none}\nWhen QPU0 was chosen by the ensemble, it made the following distribution of predictions:\nCounter({0: 55, 2: 55})\n\nWhen QPU1 was chosen by the ensemble, it made the following distribution of predictions:\nCounter({1: 37, 0: 3})\n\nDistribution of classes in iris dataset: Counter({0: 50, 2: 50, 1: 50})\n```\n:::\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These results show us that QPU0 specializes to making predictions on\nclasses 0 and 2, while QPU1 specializes to class 1.\n\nVisualization\n=============\n\nWe conclude by visualizing the correct and incorrect predictions on the\ndataset. The following function plots correctly predicted points in\ngreen and incorrectly predicted points in red.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "colours_prediction = {\"correct\": \"#83b5b9\", \"incorrect\": \"#f98d91\"}\nmarkers = [\"o\", \"v\", \"d\"]\n\n\ndef plot_points_prediction(x, y, p, title):\n    c = {0: [], 1: [], 2: []}\n    x_ = {0: [], 1: [], 2: []}\n\n    for i in range(n_samples):\n        x_[y[i]].append(x[i])\n        if p[i] == y[i]:\n            c[y[i]].append(colours_prediction[\"correct\"])\n        else:\n            c[y[i]].append(colours_prediction[\"incorrect\"])\n\n    for i in range(n_classes):\n        x_class = np.array(x_[i])\n        plt.scatter(x_class[:, 0], x_class[:, 1], c=c[i], marker=markers[i])\n\n    plt.xlabel(\"Feature 1\", fontsize=16)\n    plt.ylabel(\"Feature 2\", fontsize=16)\n    plt.title(\"Predictions from {} model\".format(title))\n\n    ax = plt.gca()\n    ax.set_aspect(1)\n\n    c_transparent = \"#00000000\"\n\n    custom_lines = [\n        Patch(\n            facecolor=colours_prediction[\"correct\"],\n            edgecolor=c_transparent, label=\"Correct\"\n        ),\n        Patch(\n            facecolor=colours_prediction[\"incorrect\"],\n            edgecolor=c_transparent, label=\"Incorrect\"\n        ),\n        Line2D([0], [0], marker=markers[0], color=c_transparent, label=\"Class 0\",\n               markerfacecolor=\"black\", markersize=10),\n        Line2D([0], [0], marker=markers[1], color=c_transparent, label=\"Class 1\",\n               markerfacecolor=\"black\", markersize=10),\n        Line2D([0], [0], marker=markers[2], color=c_transparent, label=\"Class 2\",\n               markerfacecolor=\"black\", markersize=10),\n    ]\n\n    ax.legend(handles=custom_lines, bbox_to_anchor=(1.0, 0.75))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can again compare the ensemble model with the individual models from\neach QPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_points_prediction(x, y, predictions, \"ensemble\")  # ensemble\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/demonstrations/ensemble_multi_qpu/ensemble_multi_qpu_002.png){.align-center\nwidth=\"80.0%\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_points_prediction(x, y, np.append(p_train_0, p_test_0), \"QPU0\")  # QPU 0\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/demonstrations/ensemble_multi_qpu/ensemble_multi_qpu_003.png){.align-center\nwidth=\"80.0%\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_points_prediction(x, y, np.append(p_train_1, p_test_1), \"QPU1\")  # QPU 1\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/demonstrations/ensemble_multi_qpu/ensemble_multi_qpu_004.png){.align-center\nwidth=\"80.0%\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These plots reinforce the specialization of the two QPUs. QPU1\nconcentrates on doing a good job at predicting class 1, while QPU0 is\nfocused on classes 0 and 2. By combining together, the resultant\nensemble performs better.\n\nThis tutorial shows how QPUs can work in parallel to realize a\nperformance advantage. Check out our\n`tutorial_vqe_parallel`{.interpreted-text role=\"doc\"} tutorial to see\nhow multiple QPUs can be evaluated asynchronously to speed up\ncalculating the potential energy surface of molecular hydrogen!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}