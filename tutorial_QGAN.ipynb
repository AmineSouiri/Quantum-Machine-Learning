{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quantum Generative Adversarial Networks with Cirq + TensorFlow {#quantum_GAN}\n==============================================================\n\n::: {.meta}\n:property=\\\"og:description\\\": This demo constructs and trains a Quantum\nGenerative Adversarial Network (QGAN) using PennyLane, Cirq, and\nTensorFlow. :property=\\\"og:image\\\":\n<https://pennylane.ai/qml/_images/qgan3.png>\n:::\n\n*Author: PennyLane dev team. Last updated: 15 Jan 2021.*\n\nThis demo constructs a Quantum Generative Adversarial Network (QGAN)\n([Lloyd and Weedbrook\n(2018)](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.121.040502),\n[Dallaire-Demers and Killoran\n(2018)](https://journals.aps.org/pra/abstract/10.1103/PhysRevA.98.012324))\nusing two subcircuits, a *generator* and a *discriminator*. The\ngenerator attempts to generate synthetic quantum data to match a pattern\nof \\\"real\\\" data, while the discriminator tries to discern real data\nfrom fake data (see image below). The gradient of the discriminator's\noutput provides a training signal for the generator to improve its fake\ngenerated data.\n\n| \n\n![](../demonstrations/QGAN/qgan.png){.align-center width=\"75.0%\"}\n\n| \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using Cirq + TensorFlow\n=======================\n\nPennyLane allows us to mix and match quantum devices and classical\nmachine learning software. For this demo, we will link together\nGoogle\\'s [Cirq](https://cirq.readthedocs.io/en/stable/) and\n[TensorFlow](https://www.tensorflow.org/) libraries.\n\nWe begin by importing PennyLane, NumPy, and TensorFlow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\nimport numpy as np\nimport tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also declare a 3-qubit simulator device running in Cirq.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dev = qml.device('cirq.simulator', wires=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generator and Discriminator\n===========================\n\nIn classical GANs, the starting point is to draw samples either from\nsome \\\"real data\\\" distribution, or from the generator, and feed them to\nthe discriminator. In this QGAN example, we will use a quantum circuit\nto generate the real data.\n\nFor this simple example, our real data will be a qubit that has been\nrotated (from the starting state $\\left|0\\right\\rangle$) to some\narbitrary, but fixed, state.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def real(angles, **kwargs):\n    qml.Hadamard(wires=0)\n    qml.Rot(*angles, wires=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the generator and discriminator, we will choose the same basic\ncircuit structure, but acting on different wires.\n\nBoth the real data circuit and the generator will output on wire 0,\nwhich will be connected as an input to the discriminator. Wire 1 is\nprovided as a workspace for the generator, while the discriminator's\noutput will be on wire 2.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def generator(w, **kwargs):\n    qml.Hadamard(wires=0)\n    qml.RX(w[0], wires=0)\n    qml.RX(w[1], wires=1)\n    qml.RY(w[2], wires=0)\n    qml.RY(w[3], wires=1)\n    qml.RZ(w[4], wires=0)\n    qml.RZ(w[5], wires=1)\n    qml.CNOT(wires=[0, 1])\n    qml.RX(w[6], wires=0)\n    qml.RY(w[7], wires=0)\n    qml.RZ(w[8], wires=0)\n\n\ndef discriminator(w):\n    qml.Hadamard(wires=0)\n    qml.RX(w[0], wires=0)\n    qml.RX(w[1], wires=2)\n    qml.RY(w[2], wires=0)\n    qml.RY(w[3], wires=2)\n    qml.RZ(w[4], wires=0)\n    qml.RZ(w[5], wires=2)\n    qml.CNOT(wires=[0, 2])\n    qml.RX(w[6], wires=2)\n    qml.RY(w[7], wires=2)\n    qml.RZ(w[8], wires=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create two QNodes. One where the real data source is wired up to the\ndiscriminator, and one where the generator is connected to the\ndiscriminator. In order to pass TensorFlow Variables into the quantum\ncircuits, we specify the `\"tf\"` interface.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@qml.qnode(dev, interface=\"tf\")\ndef real_disc_circuit(phi, theta, omega, disc_weights):\n    real([phi, theta, omega])\n    discriminator(disc_weights)\n    return qml.expval(qml.PauliZ(2))\n\n\n@qml.qnode(dev, interface=\"tf\")\ndef gen_disc_circuit(gen_weights, disc_weights):\n    generator(gen_weights)\n    discriminator(disc_weights)\n    return qml.expval(qml.PauliZ(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "QGAN cost functions\n===================\n\nThere are two cost functions of interest, corresponding to the two\nstages of QGAN training. These cost functions are built from two pieces:\nthe first piece is the probability that the discriminator correctly\nclassifies real data as real. The second piece is the probability that\nthe discriminator classifies fake data (i.e., a state prepared by the\ngenerator) as real.\n\nThe discriminator is trained to maximize the probability of correctly\nclassifying real data, while minimizing the probability of mistakenly\nclassifying fake data.\n\n$$Cost_D = \\mathrm{Pr}(real|\\mathrm{fake}) - \\mathrm{Pr}(real|\\mathrm{real})$$\n\nThe generator is trained to maximize the probability that the\ndiscriminator accepts fake data as real.\n\n$$Cost_G = - \\mathrm{Pr}(real|\\mathrm{fake})$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def prob_real_true(disc_weights):\n    true_disc_output = real_disc_circuit(phi, theta, omega, disc_weights)\n    # convert to probability\n    prob_real_true = (true_disc_output + 1) / 2\n    return prob_real_true\n\n\ndef prob_fake_true(gen_weights, disc_weights):\n    fake_disc_output = gen_disc_circuit(gen_weights, disc_weights)\n    # convert to probability\n    prob_fake_true = (fake_disc_output + 1) / 2\n    return prob_fake_true\n\n\ndef disc_cost(disc_weights):\n    cost = prob_fake_true(gen_weights, disc_weights) - prob_real_true(disc_weights)\n    return cost\n\n\ndef gen_cost(gen_weights):\n    return -prob_fake_true(gen_weights, disc_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training the QGAN\n=================\n\nWe initialize the fixed angles of the \\\"real data\\\" circuit, as well as\nthe initial parameters for both generator and discriminator. These are\nchosen so that the generator initially prepares a state on wire 0 that\nis very close to the $\\left| 1 \\right\\rangle$ state.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "phi = np.pi / 6\ntheta = np.pi / 2\nomega = np.pi / 7\nnp.random.seed(0)\neps = 1e-2\ninit_gen_weights = np.array([np.pi] + [0] * 8) + \\\n                   np.random.normal(scale=eps, size=(9,))\ninit_disc_weights = np.random.normal(size=(9,))\n\ngen_weights = tf.Variable(init_gen_weights)\ndisc_weights = tf.Variable(init_disc_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We begin by creating the optimizer:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.SGD(0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the first stage of training, we optimize the discriminator while\nkeeping the generator parameters fixed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cost = lambda: disc_cost(disc_weights)\n\nfor step in range(50):\n    opt.minimize(cost, disc_weights)\n    if step % 5 == 0:\n        cost_val = cost().numpy()\n        print(\"Step {}: cost = {}\".format(step, cost_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At the discriminator's optimum, the probability for the discriminator to\ncorrectly classify the real data should be close to one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Prob(real classified as real): \", prob_real_true(disc_weights).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For comparison, we check how the discriminator classifies the\ngenerator's (still unoptimized) fake data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Prob(fake classified as real): \", prob_fake_true(gen_weights, disc_weights).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the adversarial game we now have to train the generator to better\nfool the discriminator. For this demo, we only perform one stage of the\ngame. For more complex models, we would continue training the models in\nan alternating fashion until we reach the optimum point of the\ntwo-player adversarial game.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cost = lambda: gen_cost(gen_weights)\n\nfor step in range(50):\n    opt.minimize(cost, gen_weights)\n    if step % 5 == 0:\n        cost_val = cost().numpy()\n        print(\"Step {}: cost = {}\".format(step, cost_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At the optimum of the generator, the probability for the discriminator\nto be fooled should be close to 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Prob(fake classified as real): \", prob_fake_true(gen_weights, disc_weights).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At the joint optimum the discriminator cost will be close to zero,\nindicating that the discriminator assigns equal probability to both real\nand generated data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Discriminator cost: \", disc_cost(disc_weights).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The generator has successfully learned how to simulate the real data\nenough to fool the discriminator.\n\nLet\\'s conclude by comparing the states of the real data circuit and the\ngenerator. We expect the generator to have learned to be in a state that\nis very close to the one prepared in the real data circuit. An easy way\nto access the state of the first qubit is through its [Bloch\nsphere](https://en.wikipedia.org/wiki/Bloch_sphere) representation:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "obs = [qml.PauliX(0), qml.PauliY(0), qml.PauliZ(0)]\n\nbloch_vector_real = qml.map(real, obs, dev, interface=\"tf\")\nbloch_vector_generator = qml.map(generator, obs, dev, interface=\"tf\")\n\nprint(\"Real Bloch vector: {}\".format(bloch_vector_real([phi, theta, omega])))\nprint(\"Generator Bloch vector: {}\".format(bloch_vector_generator(gen_weights)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}